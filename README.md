These are seminar materials for the Geometric Methods in Machine Learning course (Spring 2024) by Prof. A.V. Bernstein at Sk.
Materials were prepared by [Oleg Kachan](https://github.com/oleg-kachan).

[Mikhail Kuznetsov](https://github.com/mmkuznecov) contributed some awesome [**course notes**](https://github.com/bekemax/GMML2024/blob/main/notes/notes.pdf) one can use to prepare for the exam.

| Seminar notebook | Theme(s) |
|---|---|
| [Sem1](https://github.com/bekemax/GMML2024/tree/main/seminar1) | [Principal Component Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) |
| [Sem2](https://github.com/bekemax/GMML2024/tree/main/seminar2) | [Independent Component Analysis (ICA)](https://en.wikipedia.org/wiki/Independent_component_analysis) |
| [Sem3](https://github.com/bekemax/GMML2024/tree/main/seminar3) | Intrinsic dimension estimation <br /> _Based on paper: Levina, Bickel (2004), [Maximum Likelihood Estimation of Intrinsic Dimension](https://papers.nips.cc/paper_files/paper/2004/hash/74934548253bcab8490ebd74afed7031-Abstract.html)_ |
| [Sem4](https://github.com/bekemax/GMML2024/tree/main/seminar4) | **[Nonlinear Dimensionality Reduction](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)** <br /> 1) [Kernel PCA](https://en.wikipedia.org/wiki/Kernel_principal_component_analysis): Gaussian, polynomial, cosine, graph kernels <br /> 2) [Metric Multidimensional Scaling (MDS)](https://en.wikipedia.org/wiki/Multidimensional_scaling) <br /> 3) [Isomap](https://en.wikipedia.org/wiki/Isomap) <br /> 4) [Locally Linear Embeddings (LLE)](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Locally-linear_embedding)  <br /> 5) [Laplacian Eigenmaps (LE)](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Laplacian_eigenmaps) <br /> 6) [Local Tangent Space Alignment (LTSA)](https://en.wikipedia.org/wiki/Local_tangent_space_alignment) <br /> 7) non-Euclidean distance mods: [p-Wasserstein](https://en.wikipedia.org/wiki/Wasserstein_metric)|
| Sem5 | **[Topological Data Analysis (TDA)](https://en.wikipedia.org/wiki/Topological_data_analysis)** <br /> 1) [Simplicial homology](https://en.wikipedia.org/wiki/Simplicial_homology), [Betti numbers](https://en.wikipedia.org/wiki/Betti_number) <br /> 2) Persistent diagrams, Wasserstein distance on them and stability <br /> 3) Persistent homology (PH) of graphs <br /> 4) Vectorization of topological features: Persistent images, Betti curves <br /> 5) Persistent homology of digital images (Obayashi, Hiraoka – https://arxiv.org/abs/1706.10082) <br /> 6) Deep sets (Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov, Smola – https://arxiv.org/abs/1703.06114)|
